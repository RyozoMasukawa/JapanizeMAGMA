{
    # image encoder settings
    encoder_name: 'clip', #CHANGED from "clip_resnet_large"
    adapter_config: {"mlp": {"adapter_type": "normal", "downsample_factor": 4}},
    freeze_img_encoder: false,
    
    # train settings 
    batch_size: 64,
    train_steps: 2000,
    lr: 8.0e-4,
    min_lr: 0.0,
    lr_decay_iters: 300000,
    image_enc_lr: 2.0e-6,
    use_image_embed_layernorm: true,
    image_embed_dropout_prob: 0.1, 
    image_size: 384,
    
    gradient_accumulation_steps: 8,
    zero_stage: 2,
    gradient_clipping: 1.0,

    # dataset / save / load settings
    train_dataset_name: 'variety of qa (tops bottoms enhanced)',
    train_dataset_dir: '/home/share_data_out/masukawa/air_project/magma/magma_japanese-gpt2-medium/dataset/air_dataset_qa_rigorous',
    eval_dataset_dir: null,
    
    #CHANGED from /home/share_data_out/masukawa/air_project/magma/magma_japanese-gpt2-medium/checkpoints/multimodal_transformer_rn50x16
    save: "/home/share_data_out/masukawa/air_project/magma/magma_japanese-gpt2-medium/checkpoints/multimodal_transformer_vit_qa_rigorous",
    
    #load: "/home/share_data_out/masukawa/air_project/magma/magma_japanese-gpt2-medium/checkpoints/multimodal_transformer_rn50x16",

    eval_every: 100,
}